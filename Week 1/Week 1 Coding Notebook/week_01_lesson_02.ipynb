{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 01 - Lesson 02 - Building Chatbots with LangChain\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook builds upon Lesson 01 by teaching you how to create functional chatbots using LangChain. You'll learn how to build conversational AI systems that can maintain context, manage memory, and provide engaging user experiences.\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "1. Understand the fundamentals of chatbot architecture in LangChain\n",
    "2. Learn how to implement conversation memory and state management\n",
    "3. Master prompt templates for chatbot interactions\n",
    "4. Implement streaming responses for better user experience\n",
    "5. Understand enterprise chatbot deployment considerations\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- **Python** installed (https://www.python.org/downloads/)\n",
    "- **Jupyter Notebook** (already installed in this environment)\n",
    "- **OpenAI API Key** (https://platform.openai.com/api-keys)\n",
    "- **LangSmith Account** (optional, for tracing and debugging)\n",
    "- The following Python libraries:\n",
    "  - `langchain` (for chatbot orchestration)\n",
    "  - `langchain-openai` (for OpenAI integration)\n",
    "  - `langgraph` (for workflow management)\n",
    "  - `pydantic` (for data validation)\n",
    "\n",
    "## Context\n",
    "\n",
    "Chatbots represent the next evolution of Chat Models, transforming them into interactive, conversational systems. They serve as:\n",
    "\n",
    "- **Customer Service Interfaces**: Automated support with human escalation capabilities\n",
    "- **Business Process Automation**: Intelligent workflow orchestration\n",
    "- **Knowledge Management Systems**: Dynamic information retrieval and synthesis\n",
    "- **User Experience Enhancers**: Personalized, context-aware interactions\n",
    "\n",
    "Understanding chatbot development is crucial for:\n",
    "- Building customer support systems\n",
    "- Creating internal knowledge assistants\n",
    "- Developing sales and marketing automation\n",
    "- Implementing intelligent business process workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's ensure we have all necessary dependencies installed and configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "%pip install -U --quiet langchain langchain-openai langgraph pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangGraph imports for chatbot workflow\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "print(\"✅ All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Chatbot Architecture in LangChain\n",
    "\n",
    "Before diving into code, let's understand the fundamental concepts of chatbot development:\n",
    "\n",
    "### Core Components\n",
    "\n",
    "1. **State Management**: Tracks conversation context and user information\n",
    "2. **Message History**: Maintains conversation flow and context\n",
    "3. **Prompt Templates**: Define chatbot behavior and personality\n",
    "4. **Workflow Engine**: Manages the flow of conversation processing\n",
    "5. **Memory System**: Persists conversation state across sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting Up the Foundation\n",
    "\n",
    "Let's start by setting up the basic components needed for our chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your OpenAI API Key here\n",
    "OPENAI_API_KEY = \"sk-your-openai-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chat Model initialized successfully!\n",
      "Model: gpt-4o-mini\n",
      "Temperature: 0.7\n",
      "Max Tokens: 1000\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chat Model\n",
    "# This will be the core intelligence of our chatbot\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # The specific model to use\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.7,  # Slightly creative for conversational responses\n",
    "    max_tokens=1000   # Reasonable response length\n",
    ")\n",
    "\n",
    "print(\"✅ Chat Model initialized successfully!\")\n",
    "print(f\"Model: {model.model_name}\")\n",
    "print(f\"Temperature: {model.temperature}\")\n",
    "print(f\"Max Tokens: {model.max_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining the Chatbot State Schema\n",
    "\n",
    "Chatbots need to maintain state across conversations. Let's define the structure for our chatbot's memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chatbot State Schema Defined!\n"
     ]
    }
   ],
   "source": [
    "# Define the state schema for our chatbot\n",
    "# This determines what information we track during conversations\n",
    "# MessagesState is a LangGraph class that manages the state of the conversation and appends messages to the conversation history\n",
    "class State(MessagesState):\n",
    "    \"\"\"The state of our chatbot conversation.\"\"\"\n",
    "    language: str\n",
    "\n",
    "print(\"✅ Chatbot State Schema Defined!\")\n",
    "\n",
    "# State Structure:\n",
    "# Messages: List of conversation messages\n",
    "# Language: String for response language preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the Prompt Template\n",
    "\n",
    "The prompt template defines how our chatbot behaves and responds. Let's create a template that behaves as a helpful, professional business assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chatbot Prompt Template Created!\n"
     ]
    }
   ],
   "source": [
    "# Create the prompt template for our chatbot\n",
    "# This defines the personality and behavior of our chatbot\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful, professional business assistant. \"\n",
    "              \"You respond in {language}. \"\n",
    "              \"Be concise, accurate, and maintain a professional tone. \"\n",
    "              \"Always be helpful and provide value to the user.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "print(\"✅ Chatbot Prompt Template Created!\")\n",
    "\n",
    "# Template Structure:\n",
    "# - System Message: Defines chatbot personality and behavior\n",
    "# - Messages Placeholder: Injects conversation history\n",
    "# - Human Input: Captures current user message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building the Chatbot Chain\n",
    "\n",
    "Now let's create the core chatbot functionality by combining our prompt template with the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chatbot Chain Created!\n",
      "\n",
      "Chain Components:\n",
      "1. Prompt Template: ChatPromptTemplate\n",
      "2. Language Model: ChatOpenAI\n",
      "3. Output Parser: StrOutputParser\n"
     ]
    }
   ],
   "source": [
    "# Create the chatbot chain\n",
    "# This combines the prompt template with the language model\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "print(\"✅ Chatbot Chain Created!\")\n",
    "\n",
    "print(\"\\nChain Components:\")\n",
    "print(f\"1. Prompt Template: {type(prompt_template).__name__}\")\n",
    "print(f\"2. Language Model: {type(model).__name__}\")\n",
    "print(f\"3. Output Parser: {type(StrOutputParser()).__name__}\")\n",
    "\n",
    "# How It Works:\n",
    "# - Prompt template formats the input with context\n",
    "# - Chain invokes the language model with the formatted input\n",
    "# - Output parser ensures consistent response format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing Basic Chatbot Functionality\n",
    "\n",
    "Let's test our basic chatbot to ensure it's working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Basic Chatbot:\n",
      "==================================================\n",
      "User: Hello! How can you help me today?\n",
      "Chatbot: Hello! I can assist you with a variety of tasks, including providing information, answering questions, helping with business strategies, offering insights on industry trends, assisting with project management, and more. How can I assist you today?\n",
      "\n",
      "✅ Basic chatbot test successful!\n"
     ]
    }
   ],
   "source": [
    "# Test the basic chatbot functionality\n",
    "# This demonstrates the fundamental interaction pattern\n",
    "try:\n",
    "    # Simple test conversation\n",
    "    test_messages = [\n",
    "        HumanMessage(content=\"Hello! How can you help me today?\")\n",
    "    ]\n",
    "    \n",
    "    print(\"Testing Basic Chatbot:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    response = chain.invoke({\n",
    "        \"messages\": test_messages,\n",
    "        \"language\": \"English\",\n",
    "        \"input\": \"Hello! How can you help me today?\"\n",
    "    })\n",
    "    \n",
    "    print(f\"User: Hello! How can you help me today?\")\n",
    "    print(f\"Chatbot: {response}\")\n",
    "    \n",
    "    print(\"\\n✅ Basic chatbot test successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"\\nMake sure you have set your OpenAI API key correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Introduction to LangGraph for Workflow Management\n",
    "\n",
    "# <p align=\"center\">\n",
    "#   <img src=\"https://substackcdn.com/image/fetch/$s_!P6kf!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe0ef3bfd-a191-4fdd-aede-6e39c811ec8a_1920x1080.png\" alt=\"LangGraph Workflow Example\" style=\"max-width: 700px; width: 60%; height: auto;\">\n",
    "# </p>\n",
    "\n",
    "Before we dive into implementing conversation memory, let's briefly introduce **LangGraph** - a powerful framework for building stateful, multi-actor applications with LLMs. We'll explore this technology in depth in future weeks, but for now, let's understand the core concepts we need for our chatbot.\n",
    "\n",
    "### What is LangGraph?\n",
    "\n",
    "LangGraph is a library for building stateful, multi-actor applications with LLMs. It's particularly powerful for:\n",
    "\n",
    "- **State Management**: Maintaining conversation context and user information across interactions\n",
    "- **Workflow Orchestration**: Managing complex conversation flows and decision trees\n",
    "- **Multi-Agent Systems**: Coordinating multiple AI agents working together\n",
    "- **Memory Persistence**: Storing and retrieving conversation history\n",
    "\n",
    "### Key LangGraph Concepts\n",
    "\n",
    "#### 1. StateGraph\n",
    "A `StateGraph` is the core building block that defines how your application manages state. Think of it as a blueprint for your chatbot's memory and behavior:\n",
    "\n",
    "```python\n",
    "# StateGraph manages the flow of your application\n",
    "workflow = StateGraph(state_schema=State)\n",
    "```\n",
    "\n",
    "#### 2. State Schema\n",
    "The state schema defines what information your chatbot remembers:\n",
    "\n",
    "```python\n",
    "class State(MessagesState):\n",
    "    \"\"\"Defines what our chatbot remembers\"\"\"\n",
    "    language: str  # User's preferred language\n",
    "    # MessagesState automatically handles conversation history\n",
    "```\n",
    "\n",
    "#### 3. Nodes and Edges\n",
    "- **Nodes**: Functions that process information (like generating responses)\n",
    "- **Edges**: Define the flow between nodes (like conversation turns)\n",
    "\n",
    "#### 4. Memory and Checkpointing\n",
    "LangGraph provides built-in memory systems that persist conversation state:\n",
    "\n",
    "```python\n",
    "# MemorySaver stores conversation history\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "```\n",
    "\n",
    "### Why LangGraph for Chatbots?\n",
    "\n",
    "Traditional chatbot approaches often struggle with:\n",
    "- **Context Loss**: Forgetting previous conversation turns\n",
    "- **State Management**: Tracking user preferences and session data\n",
    "- **Complex Flows**: Handling multi-step conversations and decision trees\n",
    "\n",
    "LangGraph solves these challenges by providing:\n",
    "- **Persistent State**: Automatic conversation history management\n",
    "- **Workflow Control**: Clear definition of conversation flows\n",
    "- **Memory Systems**: Built-in checkpointing and state persistence\n",
    "- **Scalability**: Enterprise-ready architecture for production systems\n",
    "\n",
    "### Enterprise Applications\n",
    "\n",
    "In enterprise environments, LangGraph enables:\n",
    "- **Customer Service Bots**: Multi-turn support conversations with context\n",
    "- **Sales Automation**: Lead qualification with persistent user profiles\n",
    "- **Internal Assistants**: Knowledge management with conversation history\n",
    "- **Process Automation**: Complex workflows with state tracking\n",
    "\n",
    "Now that we understand the basics, let's implement conversation memory using LangGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chatbot Workflow Created!\n"
     ]
    }
   ],
   "source": [
    "# Create a StateGraph workflow for our chatbot with memory\n",
    "# This enables multi-turn conversations and context preservation\n",
    "\n",
    "# Step 1: Initialize the StateGraph with our state schema\n",
    "# StateGraph is the core LangGraph component that manages application flow\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "# Step 2: Define the main chatbot processing function\n",
    "# This function represents a \"node\" in our workflow graph\n",
    "def call_model(state: State):\n",
    "    \"\"\"\n",
    "    Process the current state and generate a response.\n",
    "    \n",
    "    This function:\n",
    "    1. Receives the current conversation state\n",
    "    2. Extracts the latest user message\n",
    "    3. Generates an AI response using our chain\n",
    "    4. Returns the updated state with the new AI message\n",
    "    \n",
    "    Args:\n",
    "        state (State): Current conversation state containing messages and language preference\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated state with new AI message appended\n",
    "    \"\"\"\n",
    "    # Get the current input from the last human message\n",
    "    current_input = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    \n",
    "    # Generate response using our existing chain (prompt + model + parser)\n",
    "    response = chain.invoke({\n",
    "        \"messages\": state[\"messages\"],\n",
    "        \"language\": state[\"language\"],\n",
    "        \"input\": current_input\n",
    "    })\n",
    "    \n",
    "    # Create AI message and add to conversation\n",
    "    # MessagesState automatically handles message appending via reducers\n",
    "    ai_message = AIMessage(content=response)\n",
    "    \n",
    "    # Return state update - LangGraph will merge this with existing state\n",
    "    return {\"messages\": [ai_message]}\n",
    "\n",
    "# Step 3: Build the workflow graph\n",
    "# Add the processing node to our workflow\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Define the conversation flow:\n",
    "# START → model → END\n",
    "# This creates a simple linear flow for our chatbot\n",
    "workflow.add_edge(START, \"model\")  # Start conversation with model processing\n",
    "workflow.add_edge(\"model\", END)    # End after generating response\n",
    "\n",
    "print(\"✅ Chatbot Workflow Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Workflow Architecture:\n",
      "┌─────────┐    ┌─────────┐    ┌─────────┐\n",
      "│  START  │───▶│  MODEL  │───▶│   END   │\n",
      "└─────────┘    └─────────┘    └─────────┘\n",
      "   Input          Process        Output\n",
      "\n",
      "📋 Workflow Components:\n",
      "• State Schema: State\n",
      "• Processing Node: call_model()\n",
      "• Flow: Linear (START → MODEL → END)\n",
      "• Memory: MessagesState with automatic message management\n",
      "\n",
      "💡 Key Benefits:\n",
      "• Automatic state management\n",
      "• Conversation history preservation\n",
      "• Scalable workflow architecture\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔧 Workflow Architecture:\")\n",
    "print(\"┌─────────┐    ┌─────────┐    ┌─────────┐\")\n",
    "print(\"│  START  │───▶│  MODEL  │───▶│   END   │\")\n",
    "print(\"└─────────┘    └─────────┘    └─────────┘\")\n",
    "print(\"   Input          Process        Output\")\n",
    "\n",
    "print(\"\\n📋 Workflow Components:\")\n",
    "print(f\"• State Schema: {State.__name__}\")\n",
    "print(f\"• Processing Node: call_model()\")\n",
    "print(f\"• Flow: Linear (START → MODEL → END)\")\n",
    "print(f\"• Memory: MessagesState with automatic message management\")\n",
    "\n",
    "print(\"\\n💡 Key Benefits:\")\n",
    "print(\"• Automatic state management\")\n",
    "print(\"• Conversation history preservation\")\n",
    "print(\"• Scalable workflow architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chatbot Application Compiled with Memory!\n",
      "\n",
      "🧠 LangGraph Memory System:\n",
      "Checkpointer Type: InMemorySaver\n"
     ]
    }
   ],
   "source": [
    "# Compile the workflow with LangGraph's memory system\n",
    "# This enables conversation persistence and state management\n",
    "\n",
    "# Step 1: Create a memory checkpointer\n",
    "# MemorySaver is LangGraph's built-in memory system that persists conversation state\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Step 2: Compile the workflow with memory support\n",
    "# The checkpointer parameter enables state persistence across conversation turns\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"✅ Chatbot Application Compiled with Memory!\")\n",
    "\n",
    "print(\"\\n🧠 LangGraph Memory System:\")\n",
    "print(f\"Checkpointer Type: {type(memory).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Testing LangGraph-Powered Multi-Turn Conversations\n",
    "\n",
    "Now let's test our LangGraph-powered chatbot's ability to maintain conversation context and demonstrate the memory system in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing LangGraph Multi-Turn Conversation:\n",
      "============================================================\n",
      "📋 Test Scenario: Name Memory Test\n",
      "Goal: Verify that LangGraph maintains conversation context across turns\n",
      "\n",
      "🔁 Turn 1: User Introduction\n",
      "----------------------------------------\n",
      "👤 User: Hi! My name is Alice.\n",
      "🤖 Chatbot: Hello, Alice! How can I assist you today?\n",
      "\n",
      "🔁 Turn 2: Memory Test\n",
      "----------------------------------------\n",
      "👤 User: What is my name?\n",
      "🤖 Chatbot: Your name is Alice. How can I assist you further?\n",
      "\n",
      "🔁 Turn 3: Extended Context Test\n",
      "----------------------------------------\n",
      "👤 User: Can you help me with a business question?\n",
      "🤖 Chatbot: Absolutely! Please go ahead and ask your business question, and I'll do my best to assist you.\n",
      "\n",
      "✅ LangGraph Multi-turn conversation test successful!\n",
      "\n",
      "📝 Complete Conversation History:\n",
      "  1. 👤 Human: Hi! My name is Alice.\n",
      "  2. 🤖 AI: Hello, Alice! How can I assist you today?\n",
      "  3. 👤 Human: What is my name?\n",
      "  4. 🤖 AI: Your name is Alice. How can I assist you further?\n",
      "  5. 👤 Human: Can you help me with a business question?\n",
      "  6. 🤖 AI: Absolutely! Please go ahead and ask your business question, and I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "# Test LangGraph-powered multi-turn conversation with memory\n",
    "# This demonstrates the chatbot's ability to maintain context using LangGraph's state management\n",
    "\n",
    "try:\n",
    "    print(\"🧪 Testing LangGraph Multi-Turn Conversation:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Set up configuration for this conversation thread\n",
    "    # thread_id creates a unique conversation session\n",
    "    config = {\"configurable\": {\"thread_id\": \"langgraph_test_001\"}}\n",
    "    \n",
    "    print(\"📋 Test Scenario: Name Memory Test\")\n",
    "    print(\"Goal: Verify that LangGraph maintains conversation context across turns\")\n",
    "    print()\n",
    "    \n",
    "    # First interaction - User introduces themselves\n",
    "    print(\"🔁 Turn 1: User Introduction\")\n",
    "    print(\"-\" * 40)\n",
    "    messages = [HumanMessage(content=\"Hi! My name is Alice.\")]\n",
    "    language = \"English\"\n",
    "    \n",
    "    # Invoke the LangGraph application\n",
    "    # LangGraph automatically manages state and memory\n",
    "    output = app.invoke(\n",
    "        {\"messages\": messages, \"language\": language},\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    print(f\"👤 User: Hi! My name is Alice.\")\n",
    "    print(f\"🤖 Chatbot: {output['messages'][-1].content}\")\n",
    "    \n",
    "    # Second interaction - Test memory retention\n",
    "    print(\"\\n🔁 Turn 2: Memory Test\")\n",
    "    print(\"-\" * 40)\n",
    "    query = \"What is my name?\"\n",
    "    \n",
    "    # For the second turn, we only need to provide the new message\n",
    "    # LangGraph automatically retrieves the conversation history from memory\n",
    "    new_messages = [HumanMessage(content=query)]\n",
    "    \n",
    "    output = app.invoke(\n",
    "        {\"messages\": new_messages, \"language\": language},\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    print(f\"👤 User: What is my name?\")\n",
    "    print(f\"🤖 Chatbot: {output['messages'][-1].content}\")\n",
    "    \n",
    "    # Third interaction - Test continued context\n",
    "    print(\"\\n🔁 Turn 3: Extended Context Test\")\n",
    "    print(\"-\" * 40)\n",
    "    follow_up = \"Can you help me with a business question?\"\n",
    "    \n",
    "    output = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=follow_up)], \"language\": language},\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    print(f\"👤 User: Can you help me with a business question?\")\n",
    "    print(f\"🤖 Chatbot: {output['messages'][-1].content}\")\n",
    "    \n",
    "    print(\"\\n✅ LangGraph Multi-turn conversation test successful!\")\n",
    "    \n",
    "    print(\"\\n📝 Complete Conversation History:\")\n",
    "    for i, msg in enumerate(output['messages'], 1):\n",
    "        msg_type = \"👤 Human\" if isinstance(msg, HumanMessage) else \"🤖 AI\"\n",
    "        content_preview = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"  {i}. {msg_type}: {content_preview}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"• Verify your OpenAI API key is correctly set\")\n",
    "    print(\"• Check that all dependencies are installed\")\n",
    "    print(\"• Ensure you have sufficient API credits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 LangGraph Memory Analysis:\n",
      "==================================================\n",
      "📊 Total Messages in Memory: 6\n",
      "🧵 Thread ID: langgraph_test_001\n",
      "🌐 Language Preference: English\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔍 LangGraph Memory Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"📊 Total Messages in Memory: {len(output['messages'])}\")\n",
    "print(f\"🧵 Thread ID: {config['configurable']['thread_id']}\")\n",
    "print(f\"🌐 Language Preference: {output['language']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Managing Conversation History\n",
    "\n",
    "As conversations grow longer, we need to manage the message history to prevent context overflow. Let's implement message trimming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import message trimming functionality\n",
    "# This helps manage long conversations and prevent context overflow\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# Create a message trimmer\n",
    "# This ensures we don't exceed the model's context window\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=100,  # Maximum tokens to keep\n",
    "    strategy=\"last\",   # Keep the most recent messages\n",
    "    token_counter=model,  # Use our model's token counter\n",
    "    include_system=True,  # Always keep system messages\n",
    "    allow_partial=False,  # Don't allow partial messages\n",
    "    start_on=\"human\"     # Start trimming from human messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate message trimming functionality\n",
    "# This shows how the trimmer works with different message lengths\n",
    "\n",
    "# Create a long conversation for demonstration\n",
    "long_conversation = [\n",
    "    SystemMessage(content=\"You are a helpful business assistant.\"),\n",
    "    HumanMessage(content=\"Hello! I'm Bob.\"),\n",
    "    AIMessage(content=\"Hello Bob! Nice to meet you.\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream.\"),\n",
    "    AIMessage(content=\"That's a classic choice! Vanilla is very popular.\"),\n",
    "    HumanMessage(content=\"What's 2 + 2?\"),\n",
    "    AIMessage(content=\"2 + 2 equals 4.\"),\n",
    "    HumanMessage(content=\"Thanks for the math help.\"),\n",
    "    AIMessage(content=\"You're welcome! Math is fundamental.\"),\n",
    "    HumanMessage(content=\"Having fun with our conversation?\"),\n",
    "    AIMessage(content=\"Yes, absolutely! I enjoy our chat.\"),\n",
    "    HumanMessage(content=\"What's my name?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Message Trimming Demonstration:\n",
      "============================================================\n",
      "Original Messages: 12\n",
      "Original Content: 325 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"📊 Message Trimming Demonstration:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original Messages: {len(long_conversation)}\")\n",
    "print(f\"Original Content: {sum(len(str(msg.content)) for msg in long_conversation)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trimmed Messages: 8\n",
      "Trimmed Content: 208 characters\n",
      "\n",
      "Remaining Messages:\n",
      "1. SystemMessage: You are a helpful business assistant.\n",
      "2. HumanMessage: What's 2 + 2?\n",
      "3. AIMessage: 2 + 2 equals 4.\n",
      "4. HumanMessage: Thanks for the math help.\n",
      "5. AIMessage: You're welcome! Math is fundamental.\n",
      "6. HumanMessage: Having fun with our conversation?\n",
      "7. AIMessage: Yes, absolutely! I enjoy our chat.\n",
      "8. HumanMessage: What's my name?\n",
      "\n",
      "✅ Message trimming demonstration complete!\n"
     ]
    }
   ],
   "source": [
    "# Apply trimming\n",
    "trimmed_messages = trimmer.invoke(long_conversation)\n",
    "\n",
    "print(f\"\\nTrimmed Messages: {len(trimmed_messages)}\")\n",
    "print(f\"Trimmed Content: {sum(len(str(msg.content)) for msg in trimmed_messages)} characters\")\n",
    "\n",
    "print(\"\\nRemaining Messages:\")\n",
    "for i, msg in enumerate(trimmed_messages):\n",
    "    msg_type = type(msg).__name__\n",
    "    content_preview = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "    print(f\"{i+1}. {msg_type}: {content_preview}\")\n",
    "\n",
    "print(\"\\n✅ Message trimming demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Implementing Streaming Responses\n",
    "\n",
    "Streaming is crucial for chatbot user experience. Let's implement streaming to show responses as they're generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌊 Testing Streaming Responses:\n",
      "==================================================\n",
      "User: Hi I'm Todd, please tell me a joke.\n",
      "Chatbot (streaming): Hi Todd! Here’s a joke for you: \n",
      "\n",
      "Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field! \n",
      "\n",
      "I hope that brings a smile to your day!Hi Todd! Here’s a joke for you: \n",
      "\n",
      "Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field! \n",
      "\n",
      "I hope that brings a smile to your day!\n",
      "\n",
      "✅ Streaming test successful!\n",
      "\\🎥 Streaming Benefits:\n",
      "- Better user experience\n",
      "- Perceived faster responses\n",
      "- Real-time interaction\n",
      "- Reduced wait time perception\n"
     ]
    }
   ],
   "source": [
    "# Test streaming functionality\n",
    "# This demonstrates how responses can be streamed for better UX\n",
    "try:\n",
    "    print(\"🌊 Testing Streaming Responses:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Set up configuration\n",
    "    config = {\"configurable\": {\"thread_id\": \"streaming_test_001\"}}\n",
    "    \n",
    "    # Create a test message\n",
    "    query = \"Hi I'm Todd, please tell me a joke.\"\n",
    "    language = \"English\"\n",
    "    input_messages = [HumanMessage(content=query)]\n",
    "    \n",
    "    print(f\"User: {query}\")\n",
    "    print(\"Chatbot (streaming): \", end=\"\")\n",
    "    \n",
    "    # Stream the response\n",
    "    for chunk, metadata in app.stream(\n",
    "        {\"messages\": input_messages, \"language\": language},\n",
    "        config,\n",
    "        stream_mode=\"messages\"\n",
    "    ):\n",
    "        if isinstance(chunk, AIMessage):\n",
    "            print(chunk.content, end=\"\")\n",
    "    \n",
    "    print(\"\\n\\n✅ Streaming test successful!\")\n",
    "    print(\"\\🎥 Streaming Benefits:\")\n",
    "    print(\"- Better user experience\")\n",
    "    print(\"- Perceived faster responses\")\n",
    "    print(\"- Real-time interaction\")\n",
    "    print(\"- Reduced wait time perception\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"\\nMake sure you have set your OpenAI API key correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Takeaways\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "1. **Basic Chatbot Creation**: Established the fundamental pattern for building chatbots\n",
    "2. **Conversation Memory**: Implemented state management and context preservation\n",
    "3. **Message History Management**: Created systems for handling long conversations\n",
    "4. **Streaming Responses**: Implemented real-time response generation\n",
    "\n",
    "### Architecture Considerations\n",
    "\n",
    "#### Scalability\n",
    "- Chatbots can be deployed as microservices\n",
    "- Memory systems can be distributed across multiple instances\n",
    "\n",
    "#### Security\n",
    "- Conversation history must comply with data privacy regulations\n",
    "- User authentication and authorization must be implemented\n",
    "- Sensitive information should not be stored in conversation logs\n",
    "\n",
    "#### Integration\n",
    "- Chatbots can integrate with existing CRM and business systems\n",
    "- Message history can be used for analytics and improvement\n",
    "\n",
    "#### Cost Management\n",
    "- Token usage should be monitored and optimized\n",
    "- Message trimming helps control costs\n",
    "- Streaming can improve perceived performance without increasing costs\n",
    "\n",
    "### Common Enterprise Use Cases\n",
    "\n",
    "- **Customer Service**: 24/7 support with human escalation\n",
    "- **Sales Support**: Lead qualification and follow-up automation\n",
    "- **Technical Support**: First-level troubleshooting and ticket creation\n",
    "- **Internal Knowledge**: Employee self-service and information retrieval\n",
    "- **Training and Onboarding**: Interactive learning and guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Exercise: Build Your First Chatbot\n",
    "\n",
    "Now it's your turn to create a specialized chatbot for a specific business scenario. Choose one of the following exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: HR Assistant Chatbot\n",
    "# Create a chatbot that can help employees with HR-related questions\n",
    "\n",
    "def create_hr_assistant():\n",
    "    \"\"\"Create an HR assistant chatbot.\"\"\"\n",
    "    \n",
    "    # TODO: Implement your HR assistant chatbot here\n",
    "    # 1. Create a system prompt for HR assistance\n",
    "    # 2. Define HR-specific conversation flows\n",
    "    # 3. Implement appropriate responses for common HR questions\n",
    "    # 4. Test with sample HR scenarios\n",
    "    \n",
    "    print(\"👥 Exercise 1: HR Assistant Chatbot\")\n",
    "    print(\"Create a chatbot that can:\")\n",
    "    print(\"- Answer common HR questions\")\n",
    "    print(\"- Provide policy information\")\n",
    "    print(\"- Guide employees through processes\")\n",
    "    print(\"- Maintain professional HR standards\")\n",
    "    \n",
    "    return \"HR assistant implementation goes here\"\n",
    "\n",
    "# Exercise 2: Product Support Chatbot\n",
    "# Create a chatbot that can help customers with product-related questions\n",
    "\n",
    "def create_product_support():\n",
    "    \"\"\"Create a product support chatbot.\"\"\"\n",
    "    \n",
    "    # TODO: Implement your product support chatbot here\n",
    "    # 1. Create a system prompt for product support\n",
    "    # 2. Define product knowledge base integration\n",
    "    # 3. Implement troubleshooting workflows\n",
    "    # 4. Test with sample product issues\n",
    "    \n",
    "    print(\"🔧 Exercise 2: Product Support Chatbot\")\n",
    "    print(\"Create a chatbot that can:\")\n",
    "    print(\"- Answer product questions\")\n",
    "    print(\"- Guide troubleshooting steps\")\n",
    "    print(\"- Provide product information\")\n",
    "    print(\"- Escalate complex issues\")\n",
    "    \n",
    "    return \"Product support chatbot implementation goes here\"\n",
    "\n",
    "# Exercise 3: Training and Onboarding Chatbot\n",
    "# Create a chatbot that can help new employees with onboarding\n",
    "\n",
    "def create_onboarding_assistant():\n",
    "    \"\"\"Create an onboarding assistant chatbot.\"\"\"\n",
    "    \n",
    "    # TODO: Implement your onboarding assistant chatbot here\n",
    "    # 1. Create a system prompt for onboarding assistance\n",
    "    # 2. Define onboarding workflows and checklists\n",
    "    # 3. Implement progress tracking\n",
    "    # 4. Test with sample onboarding scenarios\n",
    "    \n",
    "    print(\"🎓 Exercise 3: Training and Onboarding Chatbot\")\n",
    "    print(\"Create a chatbot that can:\")\n",
    "    print(\"- Guide new employees through onboarding\")\n",
    "    print(\"- Provide training resources\")\n",
    "    print(\"- Track progress and completion\")\n",
    "    print(\"- Answer common new employee questions\")\n",
    "    \n",
    "    return \"Onboarding assistant implementation goes here\"\n",
    "\n",
    "print(\"🚀 Ready to build your first chatbot!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Conclusion\n",
    "\n",
    "Congratulations! You've successfully completed the chatbot development lesson with LangChain. You now understand:\n",
    "\n",
    "### Technical Competencies\n",
    "- How to create functional chatbots with conversation memory\n",
    "- How to implement state management and context preservation\n",
    "- How to manage conversation history and prevent context overflow\n",
    "- How to implement streaming responses for better user experience\n",
    "- How to customize chatbots for different business roles\n",
    "\n",
    "### Insights\n",
    "- The architectural implications of chatbot systems\n",
    "- How chatbots can transform customer service and business processes\n",
    "- Common use cases and implementation patterns\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next lesson, you'll learn about:\n",
    "- Building AI agents with tools and capabilities\n",
    "\n",
    "---\n",
    "\n",
    "Happy coding! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
