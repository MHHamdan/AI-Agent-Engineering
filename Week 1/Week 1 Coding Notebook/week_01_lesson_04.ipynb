{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 01 - Lesson 04 - Building Custom AI Agent Workflows with LangGraph\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook teaches you how to create custom AI agent workflows using LangGraph. You'll learn to build intelligent agents that can make decisions, execute tools, and orchestrate complex business processes.\n",
    "\n",
    "### Learning Objectives\n",
    "1. Understand LangGraph's core concepts and architecture\n",
    "2. Create custom agent workflows from scratch\n",
    "3. Integrate tools and external functions into workflows\n",
    "4. Build decision-making agents with conditional logic\n",
    "5. Understand workflow orchestration patterns\n",
    "6. Extend and customize agent capabilities\n",
    "\n",
    "## Why LangGraph?\n",
    "\n",
    "# <img src=\"https://www.qodo.ai/wp-content/uploads/2025/03/Building-Agentic-Flows-with-LangGraph.png\" alt=\"Building Agentic Flows with LangGraph\" style=\"width: 90%; height: 400px; object-fit: cover; display: block; margin-bottom: 1em;\">\n",
    "\n",
    "LangGraph is designed for building **stateful, multi-actor applications** with LLMs. Unlike simple chains, LangGraph allows you to:\n",
    "- **Maintain state** across multiple interactions\n",
    "- **Make decisions** about what to do next\n",
    "- **Coordinate multiple tools** and functions\n",
    "- **Handle complex workflows** with loops and conditions\n",
    "- **Build enterprise-grade** AI applications\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **StateGraph**: The main class for building workflows\n",
    "2. **Nodes**: Functions that process data and make decisions\n",
    "3. **Edges**: Connections that define workflow flow\n",
    "4. **State**: Data that flows through your workflow\n",
    "5. **Tools**: External functions your agent can call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, let's ensure we have all necessary dependencies installed and configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "%pip install -U --quiet langchain langchain-openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key imports explained:\n",
      "  - ToolNode: Pre-built node for executing tools\n",
      "  - StateGraph: Main class for building workflows\n",
      "  - MessagesState: State schema for message-based workflows\n",
      "  - START/END: Special nodes for workflow entry and exit\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKey imports explained:\")\n",
    "print(\"  - ToolNode: Pre-built node for executing tools\")\n",
    "print(\"  - StateGraph: Main class for building workflows\")\n",
    "print(\"  - MessagesState: State schema for message-based workflows\")\n",
    "print(\"  - START/END: Special nodes for workflow entry and exit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up the Foundation\n",
    "\n",
    "Let's start by setting up the core components: the language model and our custom tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your OpenAI API Key here\n",
    "OPENAI_API_KEY = \"sk-your-openai-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Language Model initialized successfully!\n",
      "Model: gpt-4o-mini\n",
      "Temperature: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Chat Model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.1  # Low temperature for consistent, predictable responses\n",
    ")\n",
    "\n",
    "print(\"✅ Language Model initialized successfully!\")\n",
    "print(f\"Model: {llm.model_name}\")\n",
    "print(f\"Temperature: {llm.temperature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Custom Tools\n",
    "\n",
    "`Tools` are the \"hands\" of your agent - they allow it to interact with external systems, databases, and APIs. Let's create some tools with mocked data.\n",
    "\n",
    "> **We will talk more about Tools at Week 02 but for now you just need to understand that tools are the external functions your agent can call to perform actions, like retrieving data from databases, calling APIs, or executing business logic. For this lesson, we'll focus on building the workflow structure and basic tool integration to demonstrate how agents make decisions about when and how to use these capabilities.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Custom Tools Created Successfully!\n",
      "\n",
      "🧰 Available Tools:\n",
      "1. get_customer_info: Retrieve customer data from CRM system\n",
      "2. get_sales_forecast: Get sales projections by region and period\n",
      "3. create_support_ticket: Create support tickets in ticketing system\n"
     ]
    }
   ],
   "source": [
    "# Create custom tools\n",
    "# These tools simulate real business operations that your agent can perform\n",
    "# We will talk about this in more detail at Week 02\n",
    "\n",
    "@tool\n",
    "def get_customer_info(customer_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve customer information from CRM system.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): The customer ID (e.g., CUST-001)\n",
    "        \n",
    "    Returns:\n",
    "        str: Customer information including name, tier, and spending\n",
    "        \n",
    "    Example:\n",
    "        get_customer_info(\"CUST-001\") -> Returns customer details\n",
    "    \"\"\"\n",
    "    # Mock CRM database - in production, this would call your actual CRM API\n",
    "    customer_database = {\n",
    "        \"CUST-001\": {\n",
    "            \"name\": \"John Smith\", \n",
    "            \"tier\": \"Premium\", \n",
    "            \"spend\": \"$2,500\",\n",
    "            \"last_purchase\": \"2024-01-15\",\n",
    "            \"email\": \"john.smith@email.com\"\n",
    "        },\n",
    "        \"CUST-002\": {\n",
    "            \"name\": \"Sarah Johnson\", \n",
    "            \"tier\": \"Standard\", \n",
    "            \"spend\": \"$800\",\n",
    "            \"last_purchase\": \"2024-01-10\",\n",
    "            \"email\": \"sarah.j@email.com\"\n",
    "        },\n",
    "        \"CUST-003\": {\n",
    "            \"name\": \"Mike Davis\", \n",
    "            \"tier\": \"Premium\", \n",
    "            \"spend\": \"$3,200\",\n",
    "            \"last_purchase\": \"2024-01-20\",\n",
    "            \"email\": \"mike.davis@email.com\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if customer_id in customer_database:\n",
    "        customer = customer_database[customer_id]\n",
    "        return f\"Customer {customer_id}: {customer['name']}, {customer['tier']} tier, total spend: {customer['spend']}, last purchase: {customer['last_purchase']}\"\n",
    "    \n",
    "    return f\"Customer {customer_id} not found in the system.\"\n",
    "\n",
    "@tool\n",
    "def get_sales_forecast(region: str, period: str = \"Q1 2024\") -> str:\n",
    "    \"\"\"\n",
    "    Get sales forecast from business intelligence system.\n",
    "    \n",
    "    Args:\n",
    "        region (str): Geographic region (North, South, East, West)\n",
    "        period (str): Time period for forecast (default: Q1 2024)\n",
    "        \n",
    "    Returns:\n",
    "        str: Sales forecast data for the specified region and period\n",
    "        \n",
    "    Example:\n",
    "        get_sales_forecast(\"North\", \"Q2 2024\") -> Returns forecast data\n",
    "    \"\"\"\n",
    "    # Mock BI system - in production, this would call your actual business intelligence platform\n",
    "    forecast_database = {\n",
    "        \"North\": {\n",
    "            \"Q1 2024\": \"$1.2M\", \n",
    "            \"Q2 2024\": \"$1.5M\", \n",
    "            \"Q3 2024\": \"$1.8M\",\n",
    "            \"Q4 2024\": \"$2.1M\"\n",
    "        },\n",
    "        \"South\": {\n",
    "            \"Q1 2024\": \"$800K\", \n",
    "            \"Q2 2024\": \"$950K\", \n",
    "            \"Q3 2024\": \"$1.1M\",\n",
    "            \"Q4 2024\": \"$1.3M\"\n",
    "        },\n",
    "        \"East\": {\n",
    "            \"Q1 2024\": \"$1.1M\", \n",
    "            \"Q2 2024\": \"$1.3M\", \n",
    "            \"Q3 2024\": \"$1.6M\",\n",
    "            \"Q4 2024\": \"$1.9M\"\n",
    "        },\n",
    "        \"West\": {\n",
    "            \"Q1 2024\": \"$900K\", \n",
    "            \"Q2 2024\": \"$1.1M\", \n",
    "            \"Q3 2024\": \"$1.3M\",\n",
    "            \"Q4 2024\": \"$1.6M\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if region in forecast_database and period in forecast_database[region]:\n",
    "        forecast = forecast_database[region][period]\n",
    "        return f\"Sales forecast for {region} region in {period}: {forecast}\"\n",
    "    \n",
    "    return f\"Forecast data not available for {region} region in {period}. Available periods: {list(forecast_database.get(region, {}).keys())}\"\n",
    "\n",
    "@tool\n",
    "def create_support_ticket(customer_id: str, issue_description: str, priority: str = \"Medium\") -> str:\n",
    "    \"\"\"\n",
    "    Create a support ticket in the ticketing system.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): The customer ID for the ticket\n",
    "        issue_description (str): Description of the issue or request\n",
    "        priority (str): Ticket priority (Low, Medium, High, Critical)\n",
    "        \n",
    "    Returns:\n",
    "        str: Confirmation with ticket ID and details\n",
    "        \n",
    "    Example:\n",
    "        create_support_ticket(\"CUST-001\", \"Payment failed\", \"High\") -> Creates ticket\n",
    "    \"\"\"\n",
    "    # Mock ticketing system - in production, this would create a real ticket in your system\n",
    "    import hashlib\n",
    "    import datetime\n",
    "    \n",
    "    # Generate a unique ticket ID\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    hash_input = f\"{customer_id}{issue_description}{timestamp}\"\n",
    "    ticket_hash = hashlib.md5(hash_input.encode()).hexdigest()[:8]\n",
    "    ticket_id = f\"TKT-{customer_id}-{ticket_hash}\"\n",
    "    \n",
    "    # Simulate ticket creation\n",
    "    ticket_data = {\n",
    "        \"ticket_id\": ticket_id,\n",
    "        \"customer_id\": customer_id,\n",
    "        \"issue\": issue_description,\n",
    "        \"priority\": priority,\n",
    "        \"status\": \"Open\",\n",
    "        \"created_at\": datetime.datetime.now().isoformat(),\n",
    "        \"assigned_to\": \"Support Team\"\n",
    "    }\n",
    "    \n",
    "    return f\"Support ticket {ticket_id} created successfully!\\nCustomer: {customer_id}\\nIssue: {issue_description}\\nPriority: {priority}\\nStatus: Open\\nAssigned to: Support Team\"\n",
    "\n",
    "print(\"✅ Custom Tools Created Successfully!\")\n",
    "print(\"\\n🧰 Available Tools:\")\n",
    "print(f\"1. get_customer_info: Retrieve customer data from CRM system\")\n",
    "print(f\"2. get_sales_forecast: Get sales projections by region and period\")\n",
    "print(f\"3. create_support_ticket: Create support tickets in ticketing system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding the Workflow Architecture\n",
    "\n",
    "Before we build our agent, let's understand LangGraph workflows can be structured:\n",
    "\n",
    "```\n",
    "START → LLM Node → Decision Point → Tools Node (if needed) → LLM Node → END\n",
    "```\n",
    "\n",
    "### How It Works:\n",
    "1. **START**: Workflow begins\n",
    "2. **LLM Node**: Processes user input and decides what to do\n",
    "3. **Decision Point**: Determines if tools are needed\n",
    "4. **Tools Node**: Executes tools if required\n",
    "5. **LLM Node**: Processes tool results and provides final response\n",
    "6. **END**: Workflow completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tool Integration Complete!\n"
     ]
    }
   ],
   "source": [
    "# Create tool node with available tools\n",
    "# ToolNode is a pre-built LangGraph node that handles tool execution\n",
    "tools = [get_customer_info, get_sales_forecast, create_support_ticket]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Bind tools to LLM so it knows what tools are available\n",
    "# This is crucial - the LLM needs to understand what tools it can use\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"✅ Tool Integration Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧰 Tools Available: 3\n",
      "\n",
      "🤔 What Happened:\n",
      "  - ToolNode created: Handles execution of all tools\n",
      "  - LLM bound to tools: Now knows what tools are available\n",
      "  - Ready for workflow: Tools can now be called by the agent\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🧰 Tools Available: {len(tools)}\")\n",
    "\n",
    "print(\"\\n🤔 What Happened:\")\n",
    "print(\"  - ToolNode created: Handles execution of all tools\")\n",
    "print(\"  - LLM bound to tools: Now knows what tools are available\")\n",
    "print(\"  - Ready for workflow: Tools can now be called by the agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building the Custom Agent Workflow\n",
    "\n",
    "Now we'll create the core workflow functions and assemble our agent. This is where the magic happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Workflow Functions Defined Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the core workflow functions\n",
    "# These functions define what happens at each step of our workflow\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Call the LLM to process messages and make decisions.\n",
    "    \n",
    "    This function:\n",
    "    1. Takes the current state (which contains messages)\n",
    "    2. Sends messages to the LLM (which knows about available tools)\n",
    "    3. Returns the LLM's response\n",
    "    \n",
    "    The LLM will decide whether to:\n",
    "    - Respond directly to the user\n",
    "    - Call one or more tools to gather information\n",
    "    - Ask for clarification\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Send messages to LLM - it will decide what to do\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Return the response to update the state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_tools(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    \"\"\"\n",
    "    Decide whether to execute tools or end the workflow.\n",
    "    \n",
    "    This function:\n",
    "    1. Checks the last message from the LLM\n",
    "    2. If the LLM wants to use tools, returns \"tools\"\n",
    "    3. If no tools needed, returns END to finish\n",
    "    \n",
    "    This creates the decision point in our workflow!\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if the LLM wants to use tools\n",
    "    if last_message.tool_calls:\n",
    "        print(f\"🔧 LLM wants to use tools: {len(last_message.tool_calls)} tool(s) requested\")\n",
    "        return \"tools\"\n",
    "    \n",
    "    print(\"✅ No tools needed, workflow complete\")\n",
    "    return END\n",
    "\n",
    "print(\"✅ Workflow Functions Defined Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 Custom Agent Workflow Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Now let's build the actual workflow graph\n",
    "# This is where we connect all the pieces together\n",
    "\n",
    "# Initialize the workflow using StateGraph with MessagesState\n",
    "# MessagesState is a pre-built state schema that handles message flow\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add our workflow nodes\n",
    "# Each node represents a step in our workflow\n",
    "workflow.add_node(\"LLM\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Add the workflow edges to define the flow\n",
    "# Edges determine how data moves between nodes\n",
    "workflow.add_edge(START, \"LLM\")  # Workflow starts with LLM\n",
    "workflow.add_conditional_edges(\"LLM\", call_tools)  # LLM decides: tools or end?\n",
    "workflow.add_edge(\"tools\", \"LLM\")  # Tools send results back to LLM\n",
    "\n",
    "# Compile the workflow to create an executable agent\n",
    "# This transforms our graph definition into a runnable application\n",
    "agent = workflow.compile()\n",
    "\n",
    "print(\"\\n🎉 Custom Agent Workflow Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing Our Custom Agent\n",
    "\n",
    "Now let's test our agent with different types of requests to see how it handles various scenarios. We'll use streaming to see the workflow in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Test 1: Customer Information Request\n",
      "============================================================\n",
      "User: Can you get information about customer CUST-001?\n",
      "\n",
      "Expected Behavior:\n",
      "  - LLM processes request\n",
      "  - Decides to use get_customer_info tool\n",
      "  - Tool executes and returns customer data\n",
      "  - LLM provides final response\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: HumanMessage\n",
      "💬 Content: Can you get information about customer CUST-001?...\n",
      "🔧 LLM wants to use tools: 1 tool(s) requested\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: AIMessage\n",
      "🔧 Tool Calls: 1\n",
      "  - Tool: get_customer_info\n",
      "  - Args: {'customer_id': 'CUST-001'}\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: ToolMessage\n",
      "💬 Content: Customer CUST-001: John Smith, Premium tier, total spend: $2,500, last purchase: 2024-01-15...\n",
      "✅ No tools needed, workflow complete\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: AIMessage\n",
      "💬 Content: Customer CUST-001 is John Smith, who is in the Premium tier. His total spend is $2,500, and his last purchase was on January 15, 2024....\n",
      "\n",
      "✅ Test 1 Complete!\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Customer Information Request (Requires Tool)\n",
    "print(\"🧪 Test 1: Customer Information Request\")\n",
    "print(\"=\"*60)\n",
    "print(\"User: Can you get information about customer CUST-001?\")\n",
    "print(\"\\nExpected Behavior:\")\n",
    "print(\"  - LLM processes request\")\n",
    "print(\"  - Decides to use get_customer_info tool\")\n",
    "print(\"  - Tool executes and returns customer data\")\n",
    "print(\"  - LLM provides final response\")\n",
    "\n",
    "# Execute the workflow with streaming to see each step\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [(\"user\", \"Can you get information about customer CUST-001?\")]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    # Display each step of the workflow\n",
    "    if \"messages\" in chunk and chunk[\"messages\"]:\n",
    "        last_message = chunk[\"messages\"][-1]\n",
    "        print(f\"\\n📝 Step Result:\")\n",
    "        print(f\"Message Type: {type(last_message).__name__}\")\n",
    "        \n",
    "        # Check if this is a tool call\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\"🔧 Tool Calls: {len(last_message.tool_calls)}\")\n",
    "            for tool_call in last_message.tool_calls:\n",
    "                print(f\"  - Tool: {tool_call['name']}\")\n",
    "                print(f\"  - Args: {tool_call['args']}\")\n",
    "        else:\n",
    "            print(f\"💬 Content: {last_message.content[:200]}...\")\n",
    "\n",
    "print(\"\\n✅ Test 1 Complete!\")\n",
    "\n",
    "# 🤔 What Happened:\n",
    "#   1. User asked for customer information\n",
    "#   2. LLM decided to use get_customer_info tool\n",
    "#   3. Tool executed and returned customer data\n",
    "#   4. LLM provided final response with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Test 2: Sales Forecast Request\n",
      "============================================================\n",
      "User: What's the Q2 2024 sales forecast for the North region?\n",
      "\n",
      "Expected Behavior:\n",
      "  - LLM processes request\n",
      "  - Decides to use get_sales_forecast tool\n",
      "  - Tool executes and returns forecast data\n",
      "  - LLM provides final response\n",
      "\n",
      "⌛️ Executing Workflow...\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: HumanMessage\n",
      "💬 Content: What's the Q2 2024 sales forecast for the North region?...\n",
      "🔧 LLM wants to use tools: 1 tool(s) requested\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: AIMessage\n",
      "🔧 Tool Calls: 1\n",
      "  - Tool: get_sales_forecast\n",
      "  - Args: {'region': 'North', 'period': 'Q2 2024'}\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: ToolMessage\n",
      "💬 Content: Sales forecast for North region in Q2 2024: $1.5M...\n",
      "✅ No tools needed, workflow complete\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: AIMessage\n",
      "💬 Content: The sales forecast for the North region in Q2 2024 is $1.5 million....\n",
      "\n",
      "✅ Test 2 Complete!\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Sales Forecast Request (Requires Tool)\n",
    "print(\"🧪 Test 2: Sales Forecast Request\")\n",
    "print(\"=\"*60)\n",
    "print(\"User: What's the Q2 2024 sales forecast for the North region?\")\n",
    "print(\"\\nExpected Behavior:\")\n",
    "print(\"  - LLM processes request\")\n",
    "print(\"  - Decides to use get_sales_forecast tool\")\n",
    "print(\"  - Tool executes and returns forecast data\")\n",
    "print(\"  - LLM provides final response\")\n",
    "print(\"\\n⌛️ Executing Workflow...\")\n",
    "\n",
    "# Execute the workflow\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [(\"user\", \"What's the Q2 2024 sales forecast for the North region?\")]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    if \"messages\" in chunk and chunk[\"messages\"]:\n",
    "        last_message = chunk[\"messages\"][-1]\n",
    "        print(f\"\\n📝 Step Result:\")\n",
    "        print(f\"Message Type: {type(last_message).__name__}\")\n",
    "        \n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\"🔧 Tool Calls: {len(last_message.tool_calls)}\")\n",
    "            for tool_call in last_message.tool_calls:\n",
    "                print(f\"  - Tool: {tool_call['name']}\")\n",
    "                print(f\"  - Args: {tool_call['args']}\")\n",
    "        else:\n",
    "            print(f\"💬 Content: {last_message.content[:200]}...\")\n",
    "\n",
    "print(\"\\n✅ Test 2 Complete!\")\n",
    "\n",
    "# 🤔 What Happened:\n",
    "#   1. User asked for sales forecast\n",
    "#   2. LLM decided to use get_sales_forecast tool\n",
    "#   3. Tool executed with region and period parameters\n",
    "#   4. LLM provided final response with the forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Test 3: Support Ticket Creation\n",
      "============================================================\n",
      "User: Create a high-priority support ticket for CUST-002 because their payment failed\n",
      "\n",
      "Expected Behavior:\n",
      "  - LLM processes request\n",
      "  - Decides to use create_support_ticket tool\n",
      "  - Tool executes and creates ticket\n",
      "  - LLM provides final response with ticket details\n",
      "\n",
      "⌛️ Executing Workflow...\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: HumanMessage\n",
      "💬 Content: Create a high-priority support ticket for CUST-002 because their payment failed...\n",
      "🔧 LLM wants to use tools: 1 tool(s) requested\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: AIMessage\n",
      "🔧 Tool Calls: 1\n",
      "  - Tool: create_support_ticket\n",
      "  - Args: {'customer_id': 'CUST-002', 'issue_description': 'Payment failed', 'priority': 'High'}\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: ToolMessage\n",
      "💬 Content: Support ticket TKT-CUST-002-040d078c created successfully!\n",
      "Customer: CUST-002\n",
      "Issue: Payment failed\n",
      "Priority: High\n",
      "Status: Open\n",
      "Assigned to: Support Team...\n",
      "✅ No tools needed, workflow complete\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: AIMessage\n",
      "💬 Content: A high-priority support ticket has been created successfully for customer CUST-002 due to a payment failure. \n",
      "\n",
      "- **Ticket ID:** TKT-CUST-002-040d078c\n",
      "- **Issue:** Payment failed\n",
      "- **Priority:** High\n",
      "-...\n",
      "\n",
      "✅ Test 3 Complete!\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Support Ticket Creation (Requires Tool)\n",
    "print(\"🧪 Test 3: Support Ticket Creation\")\n",
    "print(\"=\"*60)\n",
    "print(\"User: Create a high-priority support ticket for CUST-002 because their payment failed\")\n",
    "print(\"\\nExpected Behavior:\")\n",
    "print(\"  - LLM processes request\")\n",
    "print(\"  - Decides to use create_support_ticket tool\")\n",
    "print(\"  - Tool executes and creates ticket\")\n",
    "print(\"  - LLM provides final response with ticket details\")\n",
    "print(\"\\n⌛️ Executing Workflow...\")\n",
    "\n",
    "# Execute the workflow\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [(\"user\", \"Create a high-priority support ticket for CUST-002 because their payment failed\")]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    if \"messages\" in chunk and chunk[\"messages\"]:\n",
    "        last_message = chunk[\"messages\"][-1]\n",
    "        print(f\"\\n📝 Step Result:\")\n",
    "        print(f\"Message Type: {type(last_message).__name__}\")\n",
    "        \n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\"🔧 Tool Calls: {len(last_message.tool_calls)}\")\n",
    "            for tool_call in last_message.tool_calls:\n",
    "                print(f\"  - Tool: {tool_call['name']}\")\n",
    "                print(f\"  - Args: {tool_call['args']}\")\n",
    "        else:\n",
    "            print(f\"💬 Content: {last_message.content[:200]}...\")\n",
    "\n",
    "print(\"\\n✅ Test 3 Complete!\")\n",
    "\n",
    "# 🤔 What Happened:\n",
    "#   1. User requested support ticket creation\n",
    "#   2. LLM decided to use create_support_ticket tool\n",
    "#   3. Tool executed with customer ID, issue, and priority\n",
    "#   4. LLM provided final response with ticket details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Test 4: General Question (No Tools Required)\n",
      "============================================================\n",
      "User: What are the benefits of using AI agents in business?\n",
      "\n",
      "Expected Behavior:\n",
      "  - LLM processes request\n",
      "  - Decides no tools are needed\n",
      "  - Provides direct response\n",
      "  - Workflow ends immediately\n",
      "\n",
      "⌛️ Executing Workflow...\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: HumanMessage\n",
      "💬 Content: What are the benefits of using AI agents in business?...\n",
      "✅ No tools needed, workflow complete\n",
      "\n",
      "📝 Step Result:\n",
      "Message Type: AIMessage\n",
      "💬 Content: Using AI agents in business offers a variety of benefits, including:\n",
      "\n",
      "1. **Increased Efficiency**: AI agents can automate repetitive tasks, allowing employees to focus on more strategic activities. Th...\n",
      "\n",
      "✅ Test 4 Complete!\n"
     ]
    }
   ],
   "source": [
    "# Test 4: General Question (No Tools Needed)\n",
    "print(\"🧪 Test 4: General Question (No Tools Required)\")\n",
    "print(\"=\"*60)\n",
    "print(\"User: What are the benefits of using AI agents in business?\")\n",
    "print(\"\\nExpected Behavior:\")\n",
    "print(\"  - LLM processes request\")\n",
    "print(\"  - Decides no tools are needed\")\n",
    "print(\"  - Provides direct response\")\n",
    "print(\"  - Workflow ends immediately\")\n",
    "print(\"\\n⌛️ Executing Workflow...\")\n",
    "\n",
    "# Execute the workflow\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [(\"user\", \"What are the benefits of using AI agents in business?\")]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    if \"messages\" in chunk and chunk[\"messages\"]:\n",
    "        last_message = chunk[\"messages\"][-1]\n",
    "        print(f\"\\n📝 Step Result:\")\n",
    "        print(f\"Message Type: {type(last_message).__name__}\")\n",
    "        print(f\"💬 Content: {last_message.content[:200]}...\")\n",
    "\n",
    "print(\"\\n✅ Test 4 Complete!\")\n",
    "\n",
    "# 🤔 What Happened:\n",
    "#   1. User asked a general business question\n",
    "#   2. LLM processed the question\n",
    "#   3. Decided no tools were needed\n",
    "#   4. Provided direct response and ended workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Understanding the Workflow in Action\n",
    "\n",
    "Through our tests, we have observed how the workflow operates in a structured and dynamic manner. The process begins with the user providing input, which is then processed and analyzed by the Language Learning Model (LLM). At this stage, the LLM evaluates the request and determines whether the use of specialized tools is necessary. If tools are required, the workflow seamlessly executes them, after which the LLM processes the results generated by these tools. Finally, the LLM formulates and delivers a comprehensive response to the user, ensuring that the original query is fully addressed.\n",
    "\n",
    "One of the key insights from this workflow is the clear division of responsibilities: the LLM acts as the \"brain\" of the system, making all critical decisions and orchestrating the flow, while the tools serve as the \"hands,\" carrying out specific actions as directed. This architecture allows the workflow to remain highly flexible, capable of handling both straightforward and complex requests with ease. Throughout the process, the system maintains state, ensuring that context and information persist across each step. Additionally, the workflow incorporates conditional logic, enabling it to adapt dynamically based on the decisions made by the LLM.\n",
    "\n",
    "The benefits of this approach are significant. The workflow is inherently scalable, making it straightforward to introduce new tools and expand capabilities as needed. Its maintainable design, with a clear separation of concerns, facilitates ongoing development and troubleshooting. The extensibility of the system allows for the addition of new workflow nodes and logic, supporting evolving business requirements. Finally, the workflow demonstrates reliable and consistent behavior across a wide range of user requests.\n",
    "\n",
    "For those interested in exploring these concepts further, more information and advanced documentation can be found at: https://python.langchain.com/docs/langgraph/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Demonstrating the extensibility of the workflow\n",
    "\n",
    "Let's explore some capabilities that make LangGraph powerful for enterprise applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tool Created: analyze_customer_trends\n"
     ]
    }
   ],
   "source": [
    "# Let's add a new advanced tool to demonstrate extensibility\n",
    "@tool\n",
    "def analyze_customer_trends(customer_id: str, months: int = 6) -> str:\n",
    "    \"\"\"\n",
    "    Analyze customer spending trends over a specified period.\n",
    "    \n",
    "    Args:\n",
    "        customer_id (str): The customer ID to analyze\n",
    "        months (int): Number of months to analyze (default: 6)\n",
    "        \n",
    "    Returns:\n",
    "        str: Trend analysis and insights\n",
    "    \"\"\"\n",
    "    # Mock trend analysis - in production, this would analyze real transaction data\n",
    "    import random\n",
    "    \n",
    "    # Simulate monthly spending data\n",
    "    monthly_spending = [random.randint(100, 1000) for _ in range(months)]\n",
    "    total_spending = sum(monthly_spending)\n",
    "    average_spending = total_spending / months\n",
    "    \n",
    "    # Simple trend analysis\n",
    "    if monthly_spending[-1] > average_spending:\n",
    "        trend = \"increasing\"\n",
    "    elif monthly_spending[-1] < average_spending:\n",
    "        trend = \"decreasing\"\n",
    "    else:\n",
    "        trend = \"stable\"\n",
    "    \n",
    "    analysis = f\"Customer {customer_id} spending analysis over {months} months:\\n\"\n",
    "    analysis += f\"Total spending: ${total_spending:,}\\n\"\n",
    "    analysis += f\"Average monthly spending: ${average_spending:.2f}\\n\"\n",
    "    analysis += f\"Current trend: {trend}\\n\"\n",
    "    analysis += f\"Monthly breakdown: {monthly_spending}\"\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "print(\"✅ Tool Created: analyze_customer_trends\")\n",
    "\n",
    "# 🔍 Tool Capabilities:\n",
    "#   - Analyzes customer spending patterns\n",
    "#   - Provides trend insights\n",
    "#   - Generates detailed reports\n",
    "#   - Demonstrates tool extensibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Creating Agent with New Tool...\n",
      "✅ Agent Created Successfully!\n",
      "Total Tools Available: 4\n",
      "\n",
      "🧪 Testing Capabilities...\n",
      "\n",
      "User: Analyze spending trends for CUST-001 over the last 8 months\n",
      "\n",
      "💬 Final Response: Analyze spending trends for CUST-001 over the last 8 months...\n",
      "🔧 Agent using tools: 1 tool(s)\n",
      "\n",
      "🧰 Tool Call Detected:\n",
      "  - Tool: analyze_customer_trends\n",
      "  - Args: {'customer_id': 'CUST-001', 'months': 8}\n",
      "\n",
      "💬 Final Response: Customer CUST-001 spending analysis over 8 months:\n",
      "Total spending: $4,272\n",
      "Average monthly spending: $534.00\n",
      "Current trend: increasing\n",
      "Monthly breakdown: [200, 253, 746, 516, 744, 483, 568, 762]...\n",
      "\n",
      "💬 Final Response: Here's the spending analysis for customer CUST-001 over the last 8 months:\n",
      "\n",
      "- **Total Spending:** $4,272\n",
      "- **Average Monthly Spending:** $534.00\n",
      "- **Current Trend:** Increasing\n",
      "- **Monthly Breakdown:** \n",
      "  - Month 1: $200\n",
      "  - Month 2: $253\n",
      "  - Month 3: $746\n",
      "  - Month 4: $516\n",
      "  - Month 5: $744\n",
      "  - Mon...\n",
      "\n",
      "✅ Agent Test Complete!\n"
     ]
    }
   ],
   "source": [
    "# Now let's create an agent with the new tool\n",
    "# This demonstrates how easy it is to extend your agent\n",
    "\n",
    "print(\"🔄 Creating Agent with New Tool...\")\n",
    "\n",
    "# Add the new tool to our collection\n",
    "new_tools = [get_customer_info, get_sales_forecast, create_support_ticket, analyze_customer_trends]\n",
    "new_tool_node = ToolNode(new_tools)\n",
    "new_llm = llm.bind_tools(new_tools)\n",
    "\n",
    "# Build workflow\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"Model call with additional tools.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = new_llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def call_tools(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    \"\"\"Tool routing logic.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if last_message.tool_calls:\n",
    "        print(f\"🔧 Agent using tools: {len(last_message.tool_calls)} tool(s)\")\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END\n",
    "\n",
    "# Build workflow\n",
    "new_workflow = StateGraph(MessagesState)\n",
    "new_workflow.add_node(\"LLM\", call_model)\n",
    "new_workflow.add_node(\"tools\", new_tool_node)\n",
    "new_workflow.add_edge(START, \"LLM\")\n",
    "new_workflow.add_conditional_edges(\"LLM\", call_tools)\n",
    "new_workflow.add_edge(\"tools\", \"LLM\")\n",
    "\n",
    "new_agent = new_workflow.compile()\n",
    "\n",
    "print(\"✅ Agent Created Successfully!\")\n",
    "print(f\"Total Tools Available: {len(new_tools)}\")\n",
    "print(\"\\n🧪 Testing Capabilities...\")\n",
    "\n",
    "# Test the new trend analysis capability\n",
    "print(\"\\nUser: Analyze spending trends for CUST-001 over the last 8 months\")\n",
    "\n",
    "for chunk in new_agent.stream(\n",
    "    {\"messages\": [(\"user\", \"Analyze spending trends for CUST-001 over the last 8 months\")]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    if \"messages\" in chunk and chunk[\"messages\"]:\n",
    "        last_message = chunk[\"messages\"][-1]\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\"\\n🧰 Tool Call Detected:\")\n",
    "            for tool_call in last_message.tool_calls:\n",
    "                print(f\"  - Tool: {tool_call['name']}\")\n",
    "                print(f\"  - Args: {tool_call['args']}\")\n",
    "        else:\n",
    "            print(f\"\\n💬 Final Response: {last_message.content[:300]}...\")\n",
    "\n",
    "print(\"\\n✅ Agent Test Complete!\")\n",
    "\n",
    "# 🔑 Key Takeaway:\n",
    "#   Adding new tools is simple and doesn't require changing the workflow logic!\n",
    "#   The agent automatically knows about new capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "1. **Custom Agent Creation**: Built a fully functional AI agent from scratch\n",
    "2. **Tool Integration**: Successfully integrated multiple business tools\n",
    "3. **Workflow Orchestration**: Created intelligent decision-making workflows\n",
    "4. **State Management**: Implemented proper state flow and context maintenance\n",
    "5. **Extensibility**: Demonstrated how easy it is to add new capabilities\n",
    "\n",
    "### Architecture Benefits\n",
    "#### **Modularity**\n",
    "- **Separation of Concerns**: LLM handles decisions, tools handle actions\n",
    "- **Easy Extension**: Add new tools without changing workflow logic\n",
    "- **Maintainable**: Clear structure makes debugging and updates simple\n",
    "\n",
    "#### **Intelligence**\n",
    "- **LLM-Driven Decisions**: Agent intelligently chooses when to use tools\n",
    "- **Context Awareness**: Maintains understanding across complex requests\n",
    "- **Adaptive Behavior**: Workflow adapts based on user needs\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "#### **Customer Service**\n",
    "- **Automated Support**: Handle common customer inquiries\n",
    "- **Ticket Management**: Create and track support tickets\n",
    "- **Customer Insights**: Analyze customer data and trends\n",
    "\n",
    "#### **Business Intelligence**\n",
    "- **Sales Analysis**: Generate forecasts and insights\n",
    "- **Performance Tracking**: Monitor business metrics\n",
    "- **Reporting**: Automated report generation\n",
    "\n",
    "#### **Process Automation**\n",
    "- **Workflow Orchestration**: Coordinate complex business processes\n",
    "- **Decision Support**: AI-powered business decisions\n",
    "- **System Integration**: Connect multiple business applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercise: Build Your Own Agent\n",
    "\n",
    "Now it's your turn to create a specialized agent for a specific business scenario. Choose one of the following exercises or create your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ready to build your financial analysis agent!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Financial Analysis Agent\n",
    "# Create an agent that can analyze financial data and generate insights\n",
    "\n",
    "def create_financial_agent():\n",
    "    \"\"\"\n",
    "    TODO: Create a financial analysis agent with the following capabilities:\n",
    "    \n",
    "    1. Create a new tool for financial calculations (e.g., ROI, NPV, cash flow)\n",
    "    2. Add a tool for market data retrieval (e.g., stock prices, market trends)\n",
    "    3. Build a workflow that can handle financial analysis requests\n",
    "    4. Test with sample financial scenarios\n",
    "    \n",
    "    Example tools to implement:\n",
    "    - calculate_roi(initial_investment, final_value, time_period)\n",
    "    - get_market_data(symbol, period)\n",
    "    - analyze_portfolio_performance(portfolio_data)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Exercise 1: Financial Analysis Agent\n",
    "    \n",
    "    # Create an agent that can:\n",
    "    #   - Perform financial calculations\n",
    "    #   - Retrieve market data\n",
    "    #   - Generate financial insights\n",
    "    #   - Provide investment recommendations\n",
    "    \n",
    "    # TODO: Implement your financial agent here\n",
    "    \n",
    "    return \"Financial agent implementation goes here\"\n",
    "\n",
    "print(\"🚀 Ready to build your financial analysis agent!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ready to build your supply chain optimization agent!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Supply Chain Optimization Agent\n",
    "# Create an agent that can optimize supply chain operations\n",
    "\n",
    "def create_supply_chain_agent():\n",
    "    \"\"\"\n",
    "    TODO: Create a supply chain optimization agent with the following capabilities:\n",
    "    \n",
    "    1. Create a tool for inventory analysis (e.g., stock levels, reorder points)\n",
    "    2. Add a tool for demand forecasting (e.g., seasonal trends, growth patterns)\n",
    "    3. Build a workflow that can handle supply chain optimization requests\n",
    "    4. Test with sample supply chain scenarios\n",
    "    \n",
    "    Example tools to implement:\n",
    "    - analyze_inventory_levels(product_id, warehouse_id)\n",
    "    - forecast_demand(product_id, time_period)\n",
    "    - optimize_reorder_schedule(supplier_data, demand_data)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Exercise 2: Supply Chain Optimization Agent\n",
    "\n",
    "    # Create an agent that can:\n",
    "    #   - Analyze inventory levels\n",
    "    #   - Forecast demand patterns\n",
    "    #   - Optimize reorder schedules\n",
    "    #   - Reduce supply chain costs\n",
    "    \n",
    "    # TODO: Implement your supply chain agent here\n",
    "    \n",
    "    return \"Supply chain agent implementation goes here\"\n",
    "\n",
    "print(\"🚀 Ready to build your supply chain optimization agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps and Advanced Topics\n",
    "\n",
    "Congratulations! You've successfully built a custom AI agent workflow. Next week we will be covering the following topics:\n",
    "\n",
    "- Advanced LangGraph Features\n",
    "- **More about Tools**\n",
    "-**Multi-Agent Systems**\n",
    "    - **Agent Coordination**: Multiple agents working together\n",
    "    - **Specialized Roles**: Different agents for different tasks\n",
    "    - **Communication Patterns**: Agents sharing information and results\n",
    "\n",
    "### Additional Resources\n",
    "**LangGraph Documentation**: [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "1. **LangGraph Fundamentals**: Understanding the core concepts and architecture\n",
    "2. **Custom Agent Creation**: Building agents from scratch with full control\n",
    "3. **Tool Integration**: Basic tool calling\n",
    "4. **Workflow Orchestration**: Creating intelligent decision-making processes\n",
    "\n",
    "---\n",
    "\n",
    "**Happy coding!** 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
